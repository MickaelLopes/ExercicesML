{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mickael/.local/lib/python3.6/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import  pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Load Data\n",
    "First, let's load thetwo bigram file and createa dictionary and reverse dictionary to translate position and characters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bi Gram file are composed of 28 row and columns. \n",
    "- Row 1: Initial state\n",
    "- Row2-27: Alphabet characters (a to z)\n",
    "- Row 28 : final state, end of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_eng = 'bigramenglish.txt'\n",
    "file_fr = 'bigramfrancais.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = np.loadtxt(file_eng)\n",
    "fr = np.loadtxt(file_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of english bigram: (28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of english bigram: {}\".format(eng.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'1' : ' ', '2' : 'a', '3' : 'b', '4': 'c', '5' : 'd', '6' : 'e', '7': 'f',  '8' : 'g', '9' : 'h', '10': 'i', '11': 'j', '12' : 'k', '13' : 'l', '14': 'm', '15' : 'n', '16' : 'o', '17': 'p', '18' : 'q', '19' : 'r' , '20': 's',  '21' : 't', '22' : 'u', '23': 'v',  '24' : 'w', '25' : 'x' , '26': 'y',  '27' : 'z', '28' : ' ' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_inv = {v: k for k, v in dic.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Word Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which given a vec of the bi-gram will ramdomly choose the next element\n",
    "def next_el(vec):\n",
    "    t = np.random.random()\n",
    "    v = np.cumsum(vec)\n",
    "    idx = np.sum(v < t)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a word based on the be gram. Can be put a initial word sence \n",
    "def generate_el(proba, init = ' '):\n",
    "    el = []\n",
    "    if init != ' ':\n",
    "        el += init[:]\n",
    "        init = init[-1]\n",
    "        idx = int(dic_inv[init])-1\n",
    "    else : \n",
    "        idx = 0\n",
    "    while idx != 27 :\n",
    "        idx = next_el(proba[idx])\n",
    "        el += [dic[str(idx+1)]] \n",
    "    return \"\".join(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there \n",
      "then \n",
      "th \n",
      "the \n",
      "thraprererse \n",
      "the \n",
      "the \n",
      "thof \n",
      "thig \n",
      "the \n",
      "thiepledane \n",
      "thexucourshts \n",
      "theeds \n",
      "thedmathers \n",
      "th \n",
      "ther \n",
      "the \n",
      "thicorain \n",
      "therobm \n",
      "thed \n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(20):\n",
    "    a = generate_el(eng, \"th\")\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed that some of the word does not mean anything. It is normal, the function based itself on the probability of the sentence of characters but it does ensure that the  word is correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Sentence Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update our bigram for Sentence Generation, we will do two things: \n",
    "- Add a row: The new row (row 29) represent the end of the sentence.\n",
    "- Update row 28 (end of word) : The row corresponding to the end of sentence to give two new possibilites, the possibility to go back to state 1 (beginning of new word) or go to state 29 (end of sentence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update dictionnary to have caracter 29 . \n",
    "d = {'29' : '.'}\n",
    "dic.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that will change the bigram matrix and update the matrix as described above\n",
    "# In this case, we choose 0.9 as the probability to start a new word at the end of a word\n",
    "# We chose as 0.1 the probability to stop a sentence at the end of a word\n",
    "def modify_mat_dic(mat): \n",
    "    A = mat.copy()\n",
    "    n = A.shape[0]\n",
    "    new_mat = np.zeros((n+1,n+1))\n",
    "    new_mat[:-1,:-1] = A\n",
    "    new_mat[-1,-1] = 1 \n",
    "    new_mat[-2,0] = 0.9\n",
    "    new_mat[-2,-2] = 0\n",
    "    new_mat[-2,-1] = 0.1\n",
    "    return new_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq_el(proba, init = ' '):\n",
    "    el = []\n",
    "    if init != ' ':\n",
    "        el += init[:]\n",
    "        init = init[-1]\n",
    "        idx = int(dic_inv[init])-1\n",
    "    else : \n",
    "        idx = 0\n",
    "    while idx != 28 :\n",
    "        idx = next_el(proba[idx])\n",
    "        el += [dic[str(idx+1)]] \n",
    "    return \"\".join(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_modify = modify_mat_dic(eng) \n",
    "fr_modify = modify_mat_dic(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the  or .\n",
      "thritens  tharion  ss  anofen  ofeprhe  ithe  todinstigeduibar  t  ibjol  t  cedut  s  woly  thilyeaigebo  n  nathe  o  oon  sthand  duesco  by  thee  mesll  anaprnct  ororgly  a  o  ous  moronthac  bint  win  ispang  d  feedesacin  atrdeis  os  an  asen .\n",
      "they  tirs  st  sfuthee  agln  inis  baprs  tuxic  fur  a .\n",
      "tho  ioverey  d  be .\n",
      "thellipe  tick  athey  emay  hed  aly .\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(5):\n",
    "    a = generate_seq_el(eng_modify, \"th\")\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in word generation, the sentence does not mean anything as well, because they are based on probabilities only. \n",
    "At this point, we might question the  usefulness of such thing. The previous two part where just a way to manipulate and understand how a bigram  works and markov chain. The part 3 will give a practical example of how to use those bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Language recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we use the bigram to test the likelyhood of a given sentence for a given language. The strongest likelyhood will be our prediction language. \n",
    "For example, we will check the likelyhood of the sentence \"be or not to be.\" in French and English. We will see if the algorithm recognize the language. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, in order to better test more easily a sentence, a small transformation need to be made. Let's add the character '-' before each word and + at the end of each word : \n",
    "- '-' : Correspond to the first state character \n",
    "- '+' : Correspond to the end of word state\n",
    "\n",
    "Therefore a sentence like \"be or not to be.\" becomes \"-be+-or+-not+-to+-be+.\"\n",
    "We suppose that every sentence will finish with the character \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  transform_sentence(sentence): \n",
    "    s = \"\"\n",
    "    l = sentence.split(\" \")\n",
    "    for el in l : \n",
    "        s += \"+\"+el+\"-\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+to-+be-+or-+not-'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test =\"to be or not\"\n",
    "transform_sentence(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "' '",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-d8d954bf5d3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'28'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdic_vrai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdic_vrai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: ' '"
     ]
    }
   ],
   "source": [
    "# let's  create a new reverse dictionary with those updated  characters. \n",
    "# This reverse dictionary will make the translation between the sentence and the bigram matrix.\n",
    "dic_vrai = dic_inv\n",
    "d1 = {'+':'1', '-':'28'}\n",
    "dic_vrai.update(d1)\n",
    "dic_vrai.pop(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': '2',\n",
       " 'b': '3',\n",
       " 'c': '4',\n",
       " 'd': '5',\n",
       " 'e': '6',\n",
       " 'f': '7',\n",
       " 'g': '8',\n",
       " 'h': '9',\n",
       " 'i': '10',\n",
       " 'j': '11',\n",
       " 'k': '12',\n",
       " 'l': '13',\n",
       " 'm': '14',\n",
       " 'n': '15',\n",
       " 'o': '16',\n",
       " 'p': '17',\n",
       " 'q': '18',\n",
       " 'r': '19',\n",
       " 's': '20',\n",
       " 't': '21',\n",
       " 'u': '22',\n",
       " 'v': '23',\n",
       " 'w': '24',\n",
       " 'x': '25',\n",
       " 'y': '26',\n",
       " 'z': '27',\n",
       " '+': '1',\n",
       " '-': '28'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_vrai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's createa function that will read the given string and calculate its likelyhood in French and English. \n",
    "To understand this calculation, we have to consider the sentence as a markov chain. \n",
    "Therefore given a sentence S, we assume S = $(q_1, q_2, ... q_n)$ where each $q_i \\in [\"+\",\"-\",\".\",\"a\",\"b\",...\"z\"]$\n",
    "\n",
    "The likelyhood will be then calculate by $L(S) = \\Pi_{i=1}^n P(X_{i+1} = q_{i+1} | X_i = q_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit functions that will give you the probability P(X_i+i | X_i)\n",
    "def eng_vrai_next_el(init_el, next_el):\n",
    "    idx_init = int(dic_vrai[init_el]) - 1\n",
    "    idx_next = int(dic_vrai[next_el]) - 1 \n",
    "    return eng_modify[idx_init, idx_next]\n",
    "\n",
    "def fr_vrai_next_el(init_el, next_el):\n",
    "    idx_init = int(dic_vrai[init_el]) - 1\n",
    "    idx_next = int(dic_vrai[next_el]) - 1 \n",
    "    return fr_modify[idx_init, idx_next]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions that calculate the likelyhood for french and english \n",
    "def eng_vraisemblance(sentence): \n",
    "    vr = 1 \n",
    "    sentence_tr = transform_sentence(sentence)\n",
    "    for i in range(len(sentence_tr)-1):\n",
    "        vr = vr * eng_vrai_next_el(sentence_tr[i], sentence_tr[i+1])\n",
    "    return vr\n",
    "\n",
    "def fr_vraisemblance(sentence): \n",
    "    vr = 1 \n",
    "    sentence_tr = transform_sentence(sentence)\n",
    "    for i in range(len(sentence_tr)-1):\n",
    "        vr = vr * fr_vrai_next_el(sentence_tr[i], sentence_tr[i+1])\n",
    "    return vr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that tells predict if a sentence is french or english\n",
    "def language_recognition(sentence): \n",
    "    if eng_vraisemblance(sentence) > fr_vraisemblance(sentence):\n",
    "        print(\"It is a English sentence\")\n",
    "    else : \n",
    "        print(\"It is a French sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a English sentence\n"
     ]
    }
   ],
   "source": [
    "language_recognition(\"to be or not to be\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a French sentence\n"
     ]
    }
   ],
   "source": [
    "language_recognition(\"etre ou ne pas etre\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
